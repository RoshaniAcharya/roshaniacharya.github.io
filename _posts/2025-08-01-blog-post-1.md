---
title: 'Introduction to MCP'
date: 2025-08-01
permalink: /posts/2025/08/blog-post-1/
tags:
  - LLM
  - MCP
---

With the rise of **Large Language Models (LLMs)**, MCP has emerged—**Model Context Protocol**—a concept that could do for LLMs what HTML did for the web.

# What Is MCP in the World of LLMs? Understanding the Model Context Protocol

In the world of computer science, the acronym **MCP** can mean many things:  
- Master Control Program  
- Microsoft Certified Professional  
- Monte Carlo Planning  
- Mobile Content Provider  
- And now, Model Context Protocol

With the rise of **Large Language Models (LLMs)**, a new kind of MCP has emerged—**Model Context Protocol**—a concept that could do for LLMs what HTML did for the web.

## The Rise of LLMs and the Need for Standardization

The rapid advancement in LLMs has blurred the line between technical and non-technical users. From researchers to software engineers—and even your neighborhood plumber—LLMs are now a part of everyday life. People use them for:

- Education and learning  
- Entertainment  
- Coding and automation  
- Knowledge discovery  

Some of the leading LLMs include:  
- GPT by OpenAI  
- Claude by Anthropic  
- Gemini by Google  
- DeepSeek by DeepSeek  

With updates and new releases happening almost weekly, it's overwhelming to keep up—especially for developers trying to build applications on top of these models.

## The Developer's Pain Point

Every model comes with its own:  
- Input/output formatting  
- API structures  
- Prompt patterns  
- Tool integrations  

If you're trying to test a prompt on GPT, then switch to Claude or Gemini, you're likely to spend hours debugging why something breaks—even if the logic remains the same. This process is tedious, repetitive, and error-prone.

So how do you build a seamless, consistent experience across different models, tools, and data sources?

## Enter MCP – Model Context Protocol

**Model Context Protocol (MCP)** is an **open protocol** developed by Anthropic that standardizes the way AI applications interact with models, tools, and context.

Think of MCP as HTML for AI:  
- Just as HTML standardizes how content is displayed across all web browsers,  
- MCP standardizes how context is passed and actions are requested across AI models.

### Why MCP?

- Consistent experience across all AI applications  
- Easy tool and data source integration  
- Single implementation usable across multiple models  
- Reduces M×N integration complexity

Without MCP: You must manually connect M models to N tools—resulting in a mess of custom integrations.  
With MCP: Each model and tool only needs to speak MCP—resulting in a much simpler M+N setup.

## MCP Architecture: Like HTTP, but for AI

MCP follows a client-server architecture, where:

### Host

The AI application the user interacts with.  
Examples: Claude Desktop, IDEs like Cursor.

### Client

A component inside the host that communicates with a specific MCP server.  
Each server the host talks to has its own dedicated client.  
This maintains a 1:1 relationship between client and server.

### Server

An external program or service that exposes tools, resources, or capabilities via the MCP protocol.  
Examples include external APIs, code execution tools, custom agents, etc.

## Let's Build an MCP Server

In this quickstart, you'll create your own MCP server that exposes two tools:  
- `get_alerts`: Fetches weather alerts  
- `get_forecast`: Fetches weather forecasts  

Then, you'll integrate it into Claude Desktop as your MCP host.

### Prerequisites

Before you begin, make sure you're familiar with:  
- Python (intermediate level)  
- Basics of LLMs like Claude  
- Terminal commands  

### System Requirements

- Python 3.10 or higher  
- MCP SDK version 1.2.0 or higher

### Step 1: Set Up Your Project Environment

First, create a virtual environment:

```bash 
python3 -m venv weather 
```

Then, activate it:

```bash
source weather/bin/activate  # macOS/Linux
# OR
weather\Scripts\activate     # Windows
```

Install the MCP SDK:

```bash
pip install mcp>=1.0.0
```

### Step 2: Implement Your Server

Here is a basic structure using the mcp package.

```python
# server.py
import asyncio
from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.types import Resource, Tool, TextContent, ImageContent, EmbeddedResource
from pydantic import AnyUrl
import mcp.types as types

# Create a server instance
server = Server("weather-server")

@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    """
    List available tools.
    Each tool specifies its arguments using JSON Schema validation.
    """
    return [
        types.Tool(
            name="get_alerts",
            description="Get weather alerts for a location",
            inputSchema={
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "Location to get weather alerts for",
                    }
                },
                "required": ["location"],
            },
        ),
        types.Tool(
            name="get_forecast",
            description="Get weather forecast for a location",
            inputSchema={
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "Location to get weather forecast for",
                    }
                },
                "required": ["location"],
            },
        ),
    ]

@server.call_tool()
async def handle_call_tool(
    name: str, arguments: dict | None
) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:
    """
    Handle tool execution requests.
    """
    if name == "get_alerts":
        location = arguments.get("location") if arguments else "Unknown"
        return [
            types.TextContent(
                type="text",
                text=f"Weather alert for {location}: Heavy rain expected."
            )
        ]
    elif name == "get_forecast":
        location = arguments.get("location") if arguments else "Unknown"
        return [
            types.TextContent(
                type="text", 
                text=f"Forecast for {location}: Sunny with 20°C."
            )
        ]
    else:
        raise ValueError(f"Unknown tool: {name}")

async def main():
    # Import here to avoid issues with event loops
    from mcp.server.stdio import stdio_server
    
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="weather-server",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )

if __name__ == "__main__":
    asyncio.run(main())
```

### Step 3: Configure Claude Desktop

To connect your MCP server to Claude Desktop, you need to modify Claude's configuration file:

**On macOS:**
```bash
~/Library/Application Support/Claude/claude_desktop_config.json
```

**On Windows:**
```bash
%APPDATA%\Claude\claude_desktop_config.json
```

Add your server configuration:

```json
{
  "mcpServers": {
    "weather": {
      "command": "python",
      "args": ["/path/to/your/server.py"]
    }
  }
}
```

### Step 4: Test Your Server

1. Save your server code as `server.py`
2. Update the Claude Desktop configuration
3. Restart Claude Desktop
4. You should now be able to ask Claude to check weather alerts or forecasts, and it will use your MCP server tools

## Final Thoughts

The Model Context Protocol (MCP) is a powerful approach to simplify tool integration in the age of LLMs. It makes development faster, cleaner, and more scalable by removing the need to constantly adapt to different model quirks.

As LLMs become more prevalent across industries, MCP may play a foundational role in standardizing how we build and scale intelligent systems.

## Summary

- MCP is a protocol that standardizes how LLMs interact with tools and data
- Developed by Anthropic and used in apps like Claude Desktop
- Makes integration modular and scalable
- Follows a client-server model similar to HTTP
- Helps reduce complexity when building AI-powered applications